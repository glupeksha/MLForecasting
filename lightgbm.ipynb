{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import lightgbm as lgb\n",
    "\n",
    "%matplotlib inline\n",
    "data_path = 'data/'\n",
    "seed=1204\n",
    "\n",
    "submission_path=data_path+'submission/'\n",
    "fold_path = 'fold_data/'\n",
    "\n",
    "\n",
    "cv_loss_list=[]\n",
    "n_iteration_list=[]\n",
    "def score(params):\n",
    "    print(\"Training with params: \")\n",
    "    print(params)\n",
    "    cv_losses=[]\n",
    "    cv_iteration=[]\n",
    "    for (train_idx,val_idx) in cv:\n",
    "        cv_train = X.iloc[train_idx]\n",
    "        cv_val = X.iloc[val_idx]\n",
    "        cv_y_train = y[train_idx]\n",
    "        cv_y_val = y[val_idx]\n",
    "        lgb_model = lgb.train(params, lgb.Dataset(cv_train, label=cv_y_train), 2000, \n",
    "                          lgb.Dataset(cv_val, label=cv_y_val), verbose_eval=False, \n",
    "                          early_stopping_rounds=100)\n",
    "       \n",
    "        train_pred = lgb_model.predict(cv_train,lgb_model.best_iteration+1)\n",
    "        val_pred = lgb_model.predict(cv_val,lgb_model.best_iteration+1)\n",
    "        \n",
    "        val_loss = root_mean_squared_error(cv_y_val,val_pred)\n",
    "        train_loss = root_mean_squared_error(cv_y_train,train_pred)\n",
    "        print('Train RMSE: {}. Val RMSE: {}'.format(train_loss,val_loss))\n",
    "        print('Best iteration: {}'.format(lgb_model.best_iteration))\n",
    "        cv_losses.append(val_loss)\n",
    "        cv_iteration.append(lgb_model.best_iteration)\n",
    "    print('6 fold results: {}'.format(cv_losses))\n",
    "    cv_loss_list.append(cv_losses)\n",
    "    n_iteration_list.append(cv_iteration)\n",
    "    \n",
    "    mean_cv_loss = np.mean(cv_losses)\n",
    "    print('Average iterations: {}'.format(np.mean(cv_iteration)))\n",
    "    print(\"Mean Cross Validation RMSE: {}\\n\".format(mean_cv_loss))\n",
    "    return {'loss': mean_cv_loss, 'status': STATUS_OK}\n",
    "\n",
    "def optimize(space,seed=seed,max_evals=5):\n",
    "    \n",
    "    best = fmin(score, space, algo=tpe.suggest, \n",
    "        # trials=trials, \n",
    "        max_evals=max_evals)\n",
    "    return best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = get_all_data(data_path,'new_sales_lag_after12.pickle')\n",
    "\n",
    "X,y = get_X_y(all_data,33)\n",
    "X.drop('date_block_num',axis=1,inplace=True)\n",
    "cv = get_cv_idxs(all_data,28,33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>shop_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>date_block_num</th>\n",
       "      <th>item_cnt_month</th>\n",
       "      <th>item_category_id</th>\n",
       "      <th>item_cat_block_target_sum</th>\n",
       "      <th>item_cat_block_target_mean</th>\n",
       "      <th>item_block_target_sum</th>\n",
       "      <th>item_block_target_mean</th>\n",
       "      <th>shop_block_target_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>item_block_target_sum_lag_12</th>\n",
       "      <th>item_block_target_mean_lag_12</th>\n",
       "      <th>shop_block_target_sum_lag_12</th>\n",
       "      <th>shop_block_target_mean_lag_12</th>\n",
       "      <th>item_cnt_month_lag_12</th>\n",
       "      <th>December</th>\n",
       "      <th>Newyear_Xmas</th>\n",
       "      <th>Valentine_MenDay</th>\n",
       "      <th>WomenDay</th>\n",
       "      <th>Easter_Labor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>54</td>\n",
       "      <td>10297</td>\n",
       "      <td>12</td>\n",
       "      <td>4.0</td>\n",
       "      <td>37</td>\n",
       "      <td>7511.0</td>\n",
       "      <td>1.017199</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>1.228323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>10296</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>38</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>1.002132</td>\n",
       "      <td>17</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>1.228323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>54</td>\n",
       "      <td>10298</td>\n",
       "      <td>12</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40</td>\n",
       "      <td>22065.0</td>\n",
       "      <td>1.105627</td>\n",
       "      <td>182</td>\n",
       "      <td>1.181818</td>\n",
       "      <td>8198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>1.228323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>10300</td>\n",
       "      <td>12</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37</td>\n",
       "      <td>7511.0</td>\n",
       "      <td>1.017199</td>\n",
       "      <td>26</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>8198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>1.228323</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>10284</td>\n",
       "      <td>12</td>\n",
       "      <td>1.0</td>\n",
       "      <td>57</td>\n",
       "      <td>984.0</td>\n",
       "      <td>1.004082</td>\n",
       "      <td>3</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8198</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4094.0</td>\n",
       "      <td>1.228323</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   shop_id  item_id  date_block_num  item_cnt_month  item_category_id  \\\n",
       "0       54    10297              12             4.0                37   \n",
       "1       54    10296              12             3.0                38   \n",
       "2       54    10298              12            14.0                40   \n",
       "3       54    10300              12             3.0                37   \n",
       "4       54    10284              12             1.0                57   \n",
       "\n",
       "   item_cat_block_target_sum  item_cat_block_target_mean  \\\n",
       "0                     7511.0                    1.017199   \n",
       "1                     1410.0                    1.002132   \n",
       "2                    22065.0                    1.105627   \n",
       "3                     7511.0                    1.017199   \n",
       "4                      984.0                    1.004082   \n",
       "\n",
       "   item_block_target_sum  item_block_target_mean  shop_block_target_sum  \\\n",
       "0                     23                1.000000                   8198   \n",
       "1                     17                1.000000                   8198   \n",
       "2                    182                1.181818                   8198   \n",
       "3                     26                0.962963                   8198   \n",
       "4                      3                1.000000                   8198   \n",
       "\n",
       "       ...       item_block_target_sum_lag_12  item_block_target_mean_lag_12  \\\n",
       "0      ...                                1.0                            1.0   \n",
       "1      ...                                1.0                            1.0   \n",
       "2      ...                                1.0                            1.0   \n",
       "3      ...                                1.0                            1.0   \n",
       "4      ...                                1.0                            1.0   \n",
       "\n",
       "   shop_block_target_sum_lag_12  shop_block_target_mean_lag_12  \\\n",
       "0                        4094.0                       1.228323   \n",
       "1                        4094.0                       1.228323   \n",
       "2                        4094.0                       1.228323   \n",
       "3                        4094.0                       1.228323   \n",
       "4                        4094.0                       1.228323   \n",
       "\n",
       "   item_cnt_month_lag_12  December  Newyear_Xmas  Valentine_MenDay  WomenDay  \\\n",
       "0                    0.0         0             1                 0         0   \n",
       "1                    1.0         0             1                 0         0   \n",
       "2                    0.0         0             1                 0         0   \n",
       "3                    1.0         0             1                 0         0   \n",
       "4                    0.0         0             1                 0         0   \n",
       "\n",
       "   Easter_Labor  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-af8bca0a36b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with params: \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.225, 'metric': 'rmse', 'min_data_in_leaf': 21, 'objective': 'regression', 'seed': 1204, 'subsample': 0.55}\n",
      "Train RMSE: 0.9437302156786905. Val RMSE: 0.9366247446255378\n",
      "Best iteration: 63\n",
      "Train RMSE: 0.8276789817081904. Val RMSE: 0.9188494496674715\n",
      "Best iteration: 304\n",
      "Train RMSE: 0.8525493410274808. Val RMSE: 0.8413888536472223\n",
      "Best iteration: 227\n",
      "Train RMSE: 0.8661577934688117. Val RMSE: 0.9028903593689085\n",
      "Best iteration: 184\n",
      "Train RMSE: 0.8943269270488873. Val RMSE: 0.9948535715384942\n",
      "Best iteration: 124\n",
      "Train RMSE: 0.978147467028635. Val RMSE: 0.9897792879987152\n",
      "Best iteration: 28\n",
      "6 fold results: [0.9366247446255378, 0.9188494496674715, 0.8413888536472223, 0.9028903593689085, 0.9948535715384942, 0.9897792879987152]\n",
      "Average iterations: 155.0\n",
      "Mean Cross Validation RMSE: 0.9307310444743916\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.8, 'learning_rate': 0.30000000000000004, 'metric': 'rmse', 'min_data_in_leaf': 6, 'objective': 'regression', 'seed': 1204, 'subsample': 0.8500000000000001}\n",
      "Train RMSE: 0.9786558118696927. Val RMSE: 0.953102197359679\n",
      "Best iteration: 28\n",
      "Train RMSE: 0.8739364997067933. Val RMSE: 0.9138712489991874\n",
      "Best iteration: 137\n",
      "Train RMSE: 0.7782667509169637. Val RMSE: 0.8718713629921506\n",
      "Best iteration: 380\n",
      "Train RMSE: 0.8734128013498035. Val RMSE: 0.8987108975873647\n",
      "Best iteration: 123\n",
      "Train RMSE: 0.8882233276134746. Val RMSE: 1.0038988676438019\n",
      "Best iteration: 101\n",
      "Train RMSE: 0.9193039503035475. Val RMSE: 0.9763128754195443\n",
      "Best iteration: 63\n",
      "6 fold results: [0.953102197359679, 0.9138712489991874, 0.8718713629921506, 0.8987108975873647, 1.0038988676438019, 0.9763128754195443]\n",
      "Average iterations: 138.66666666666666\n",
      "Mean Cross Validation RMSE: 0.936294575000288\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.9, 'learning_rate': 0.1, 'metric': 'rmse', 'min_data_in_leaf': 29, 'objective': 'regression', 'seed': 1204, 'subsample': 0.8}\n",
      "Train RMSE: 0.8674941091668535. Val RMSE: 0.9139589041598194\n",
      "Best iteration: 402\n",
      "Train RMSE: 0.7782490792933175. Val RMSE: 0.906585467637047\n",
      "Best iteration: 1159\n",
      "Train RMSE: 0.7752620270770066. Val RMSE: 0.8406689793367524\n",
      "Best iteration: 1176\n",
      "Train RMSE: 0.8513074601189365. Val RMSE: 0.8953727066495695\n",
      "Best iteration: 472\n",
      "Train RMSE: 0.8550103890529427. Val RMSE: 0.988085491179386\n",
      "Best iteration: 440\n",
      "Train RMSE: 0.7431691986671404. Val RMSE: 0.9550323874860447\n",
      "Best iteration: 1755\n",
      "6 fold results: [0.9139589041598194, 0.906585467637047, 0.8406689793367524, 0.8953727066495695, 0.988085491179386, 0.9550323874860447]\n",
      "Average iterations: 900.6666666666666\n",
      "Mean Cross Validation RMSE: 0.9166173227414364\n",
      "\n",
      "Training with params: \n",
      "{'colsample_bytree': 0.5, 'learning_rate': 0.1, 'metric': 'rmse', 'min_data_in_leaf': 11, 'objective': 'regression', 'seed': 1204, 'subsample': 0.9500000000000001}\n",
      "Train RMSE: 0.9274120698110006. Val RMSE: 0.9193049736562362\n",
      "Best iteration: 190\n",
      "Train RMSE: 0.8696473338108204. Val RMSE: 0.9140376630114732\n",
      "Best iteration: 415\n"
     ]
    }
   ],
   "source": [
    "space = {\n",
    "#     'max_depth': hp.choice('max_depth', np.arange(3, 15, dtype=int)),\n",
    "    'subsample': hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "    'colsample_bytree': hp.quniform('colsample_bytree', 0.5, 1, 0.05),\n",
    "    'min_data_in_leaf': hp.choice('min_data_in_leaf',np.arange(5, 30,1, dtype=int)),\n",
    "    'learning_rate': hp.quniform('learning_rate', 0.025, 0.5, 0.025),\n",
    "    'seed':seed,\n",
    "    'objective': 'regression',\n",
    "    'metric':'rmse',\n",
    "}\n",
    "best_hyperparams = optimize(space,max_evals=5)\n",
    "print(\"The best hyperparameters are: \")\n",
    "print(best_hyperparams)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = get_all_data(data_path,'new_sales_lag_after12.pickle')\n",
    "\n",
    "X,y = get_X_y(all_data,33)\n",
    "X.drop('date_block_num',axis=1,inplace=True)\n",
    "\n",
    "cv = get_cv_idxs(all_data,28,33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = {\n",
    "               'colsample_bytree': 0.8,\n",
    "               'metric': 'rmse',\n",
    "               'min_data_in_leaf': 21, \n",
    "               'subsample': 0.55, \n",
    "               'learning_rate': 0.225, \n",
    "               'objective': 'regression', \n",
    "               'bagging_seed': 128, \n",
    "               'num_leaves': 128,\n",
    "               'bagging_freq':1,\n",
    "               'seed':1204\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10]\tvalid_0's rmse: 2.20369\n",
      "[20]\tvalid_0's rmse: 2.04988\n",
      "[30]\tvalid_0's rmse: 1.98889\n",
      "[40]\tvalid_0's rmse: 1.93211\n",
      "[50]\tvalid_0's rmse: 1.89621\n",
      "[60]\tvalid_0's rmse: 1.86918\n",
      "[70]\tvalid_0's rmse: 1.84547\n",
      "[80]\tvalid_0's rmse: 1.8276\n",
      "[90]\tvalid_0's rmse: 1.80814\n",
      "[100]\tvalid_0's rmse: 1.79248\n",
      "[110]\tvalid_0's rmse: 1.77737\n",
      "[120]\tvalid_0's rmse: 1.76527\n",
      "[130]\tvalid_0's rmse: 1.75302\n",
      "[140]\tvalid_0's rmse: 1.74165\n",
      "[150]\tvalid_0's rmse: 1.73041\n",
      "[160]\tvalid_0's rmse: 1.72031\n",
      "[170]\tvalid_0's rmse: 1.70966\n",
      "[180]\tvalid_0's rmse: 1.70209\n",
      "[190]\tvalid_0's rmse: 1.69364\n",
      "[200]\tvalid_0's rmse: 1.68329\n",
      "[210]\tvalid_0's rmse: 1.67472\n",
      "[220]\tvalid_0's rmse: 1.66513\n",
      "[230]\tvalid_0's rmse: 1.65829\n",
      "[240]\tvalid_0's rmse: 1.64898\n",
      "[250]\tvalid_0's rmse: 1.63801\n",
      "[260]\tvalid_0's rmse: 1.63096\n",
      "[270]\tvalid_0's rmse: 1.62359\n",
      "[280]\tvalid_0's rmse: 1.61482\n",
      "[290]\tvalid_0's rmse: 1.6068\n",
      "[300]\tvalid_0's rmse: 1.60125\n",
      "[310]\tvalid_0's rmse: 1.5948\n",
      "[320]\tvalid_0's rmse: 1.58852\n",
      "[330]\tvalid_0's rmse: 1.58173\n",
      "[340]\tvalid_0's rmse: 1.5759\n",
      "[350]\tvalid_0's rmse: 1.57045\n",
      "[360]\tvalid_0's rmse: 1.56469\n",
      "[370]\tvalid_0's rmse: 1.55691\n",
      "[380]\tvalid_0's rmse: 1.55107\n",
      "[390]\tvalid_0's rmse: 1.54659\n",
      "[400]\tvalid_0's rmse: 1.54116\n",
      "[410]\tvalid_0's rmse: 1.53609\n",
      "[420]\tvalid_0's rmse: 1.52852\n",
      "[430]\tvalid_0's rmse: 1.5226\n",
      "[440]\tvalid_0's rmse: 1.51747\n",
      "[450]\tvalid_0's rmse: 1.51063\n",
      "[460]\tvalid_0's rmse: 1.50429\n",
      "[470]\tvalid_0's rmse: 1.49933\n",
      "[480]\tvalid_0's rmse: 1.49475\n",
      "[490]\tvalid_0's rmse: 1.4896\n",
      "[500]\tvalid_0's rmse: 1.48447\n",
      "[510]\tvalid_0's rmse: 1.48007\n",
      "[520]\tvalid_0's rmse: 1.47504\n",
      "[530]\tvalid_0's rmse: 1.47128\n",
      "[540]\tvalid_0's rmse: 1.46683\n",
      "[550]\tvalid_0's rmse: 1.46209\n",
      "[560]\tvalid_0's rmse: 1.45702\n",
      "[570]\tvalid_0's rmse: 1.45214\n",
      "[580]\tvalid_0's rmse: 1.44799\n",
      "[590]\tvalid_0's rmse: 1.44387\n",
      "[600]\tvalid_0's rmse: 1.44039\n",
      "[610]\tvalid_0's rmse: 1.43637\n",
      "[620]\tvalid_0's rmse: 1.43307\n",
      "[630]\tvalid_0's rmse: 1.42912\n",
      "[640]\tvalid_0's rmse: 1.42566\n",
      "[650]\tvalid_0's rmse: 1.4218\n",
      "[660]\tvalid_0's rmse: 1.41915\n",
      "[670]\tvalid_0's rmse: 1.41622\n",
      "[680]\tvalid_0's rmse: 1.41274\n",
      "[690]\tvalid_0's rmse: 1.40809\n",
      "[700]\tvalid_0's rmse: 1.40473\n"
     ]
    }
   ],
   "source": [
    "lgb_model_full = lgb.train(lgb_params, lgb.Dataset(X, label=y), 708, \n",
    "                      lgb.Dataset(X, label=y), verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test = pd.read_csv(os.path.join(data_path, 'x_test_data.csv'))\n",
    "test.drop(['date_block_num'],axis=1,inplace=True)\n",
    "test_pred = lgb_model_full.predict(test,708)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#item_cnt_month = np.clip(item_cnt_month,0,clip)\n",
    "test= pd.read_csv(os.path.join(data_path, 'test.csv.gz'))\n",
    "sub = test.copy()\n",
    "sub['item_cnt_month'] = test_pred\n",
    "sub.drop(['item_id','shop_id'],axis=1,inplace=True)\n",
    "sub.to_csv('submissions/' + \"lightgbm\"+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x21580885588>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(test_pred).hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
